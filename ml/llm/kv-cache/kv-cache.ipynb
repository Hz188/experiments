{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c43875ce-045f-4d01-9ea6-b60d4c46c601",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:12:24.262987Z",
     "iopub.status.busy": "2024-06-15T03:12:24.262633Z",
     "iopub.status.idle": "2024-06-15T03:12:24.271264Z",
     "shell.execute_reply": "2024-06-15T03:12:24.268981Z",
     "shell.execute_reply.started": "2024-06-15T03:12:24.262963Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7897'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7897'\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01509095-61e2-4012-ada4-8194d47e969b",
   "metadata": {},
   "source": [
    "- attention mechanism （Transformer 最特色的）\n",
    "    - $X\\in\\mathbb R^{\\ell\\times d}$\n",
    "    - $W_k\\in\\mathbb R^{d\\times d_k},W_q\\in\\mathbb R^{d\\times d_k},W_v\\in\\mathbb R^{d\\times d_v}$\n",
    "    - $Q=XW_q\\in\\mathbb R^{\\ell\\times d_k}, K=XW_k\\in\\mathbb R^{\\ell\\times d_k}, V=XW_v\\in\\mathbb R^{\\ell\\times d_v}$\n",
    "\n",
    "$$\n",
    "\\left(\\text{Attention}(Q,K,V)=\\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\\right)\\in \\mathbb R^{\\ell\\times d_v}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba27bc3-1a8e-403d-9853-2849c1919132",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T01:59:15.133701Z",
     "iopub.status.busy": "2024-06-15T01:59:15.133125Z",
     "iopub.status.idle": "2024-06-15T01:59:15.144843Z",
     "shell.execute_reply": "2024-06-15T01:59:15.142842Z",
     "shell.execute_reply.started": "2024-06-15T01:59:15.133657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/v2/resize:fit:828/format:webp/1*uyuyOW1VBqmF5Gtv225XHQ.gif\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://miro.medium.com/v2/resize:fit:828/format:webp/1*uyuyOW1VBqmF5Gtv225XHQ.gif', width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e6a107-727f-4c5d-956c-646a24a94fc5",
   "metadata": {},
   "source": [
    "- KV cache 会显著地提升 inference/generate 的性能，降低时延；\n",
    "- generate 的 seq 越长，占用的显存增长得也会更多；\n",
    "    - gpt 8K vs. 32k, input/output prices 是翻倍的关系\n",
    "- KV-cache Memory Usage\n",
    "\n",
    "    $$\n",
    "    2 \\times \\text{precision} \\times n_{\\text{layers}} \\times d_{\\text{model}} \\times \\text{seqlen} \\times \\text{batch}\n",
    "    $$\n",
    "    \n",
    "    - 2 = two matrices for K and V\n",
    "    - precision = bytes per parameter (e.g., 4 for fp32)\n",
    "    - $n_{\\text{layers}}$ = layers in the model\n",
    "    - $d_{\\text{model}}$ = dimension of embeddings\n",
    "    - seqlen = length of context in tokens\n",
    "    - batch = batch size\n",
    "    - OPT-30B: $2*2*48*128*1024*7168$\n",
    "        - precision：2（fp16 inference）\n",
    "        - 48 layers，128 batch\n",
    "        - K/V shape: seqlen 1024, d_model 7168 (7*1024)\n",
    "            - https://github.com/meta-llama/llama3/blob/main/llama/model.py#L129-L144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca2985d1-5354-455d-8f26-a66f5d9154f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:08:50.749174Z",
     "iopub.status.busy": "2024-06-15T03:08:50.748551Z",
     "iopub.status.idle": "2024-06-15T03:08:50.760900Z",
     "shell.execute_reply": "2024-06-15T03:08:50.759381Z",
     "shell.execute_reply.started": "2024-06-15T03:08:50.749128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KV-cache: 168GB\n",
    "# Model: 2*30B=60GB\n",
    "2*2*48*128*1024*7168/(1024*1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b06238f-f28d-4b74-aef6-4d2d0bf8c277",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T16:19:37.311005Z",
     "iopub.status.busy": "2024-06-13T16:19:37.310412Z",
     "iopub.status.idle": "2024-06-13T16:37:11.069672Z",
     "shell.execute_reply": "2024-06-13T16:37:11.068823Z",
     "shell.execute_reply.started": "2024-06-13T16:19:37.310963Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):  \u001b[38;5;66;03m# measuring 10 generations\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is KV caching?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     times\u001b[38;5;241m.\u001b[39mappend(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwith\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39muse_cache\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwithout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m KV caching: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(times),\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m +- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(np\u001b[38;5;241m.\u001b[39mstd(times),\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/dlsys/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dlsys/lib/python3.11/site-packages/transformers/generation/utils.py:1914\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1906\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1907\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1908\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1909\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1910\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1911\u001b[0m     )\n\u001b[1;32m   1913\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1914\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1927\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1928\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1929\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1931\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/dlsys/lib/python3.11/site-packages/transformers/generation/utils.py:2651\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2648\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2650\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2651\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2652\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2654\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2655\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2656\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2659\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dlsys/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dlsys/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dlsys/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:1443\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mset_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1441\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1443\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1445\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1447\u001b[0m     \u001b[38;5;66;03m# move labels to correct device to enable model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dlsys/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dlsys/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dlsys/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\").to(device)\n",
    "\n",
    "for use_cache in (True, False):\n",
    "    times = []\n",
    "    for _ in range(3):  # measuring 10 generations\n",
    "        start = time.time()\n",
    "        model.generate(**tokenizer(\"What is KV caching?\", return_tensors=\"pt\").to(device), \n",
    "                        use_cache=use_cache, max_new_tokens=1000)\n",
    "        times.append(time.time() - start)\n",
    "    print(f\"{'with' if use_cache else 'without'} KV caching: {round(np.mean(times), 3)} +- {round(np.std(times), 3)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fae4c1-ee62-4c46-860d-f725b43c4d59",
   "metadata": {},
   "source": [
    "## encoder-decoder vs. decoder only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "531aa1d9-b49a-49a9-977d-01391c5af548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T01:59:10.811339Z",
     "iopub.status.busy": "2024-06-15T01:59:10.810736Z",
     "iopub.status.idle": "2024-06-15T01:59:10.828409Z",
     "shell.execute_reply": "2024-06-15T01:59:10.826324Z",
     "shell.execute_reply.started": "2024-06-15T01:59:10.811296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../../../assets/imgs/ml/llm/kv-cache/multi-turn-bi-uni.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='../../../assets/imgs/ml/llm/kv-cache/multi-turn-bi-uni.png', width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a44bfa8-f06a-4f66-8680-80ef70c81d70",
   "metadata": {},
   "source": [
    "- Bidirectional vs. Unidirectional\n",
    "    - BERT：**Bidirectional** Encoder Representations from Transformers），双向注意力\n",
    "    - GPT：Unidirectional，单向注意力；\n",
    "- 以多轮对话为例，从计算复杂度的角度探索为什么 decoder-only 更优\n",
    "- 定义\n",
    "    - $L$: past sequence length\n",
    "    - $\\ell$: 新的输入的长度\n",
    "    - $d$：embedding dimension\n",
    "- decoder only\n",
    "    - KVcache: $K_{past}, V_{past}$\n",
    "    - 每次新输入时，计算键值（$K_{new}, V_{new}$），时间复杂度为 $O(\\ell\\cdot d)$，也需要计算 Query $Q_{new}$\n",
    "    - 计算注意力，\n",
    "        - $Q=Q_{new}\\in \\mathbb R^{\\ell \\cdot d}$\n",
    "        - $K=[K_{past}, K_{new}]\\in \\mathbb R^{(L+\\ell)\\cdot d}$\n",
    "        - $V=[V_{past}, V_{new}]\\in \\mathbb R^{(L+\\ell)\\cdot d}$\n",
    "        - $A=QK^T\\in \\mathbb R^{\\ell\\cdot(\\ell+L)}$\n",
    "            - $q_i$ 要跟 $L+i$ 的 K 计算 score vector；\n",
    "        - $\\text{softmax}(A)\\cdot V\\in \\mathbb R^{\\ell\\cdot d}$\n",
    "- 对于 encoder-decoder\n",
    "    - At every turn, the new input has to be **encoded again**; for unidirectional attention, only the newly added message needs to be encoded.\n",
    "    - 看图：每次新来token必须重新计算所有token的交互，先前的token也要再次计算，而Decoder only的不需要，来一个加一个就行 -> 一切都为了计算效率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776d34b8-fb9f-4c5c-9e8a-5da36bcacc31",
   "metadata": {},
   "source": [
    "## demo tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b899c2af-0dfd-4b0f-911f-90871ed979e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:12:27.943412Z",
     "iopub.status.busy": "2024-06-15T03:12:27.942777Z",
     "iopub.status.idle": "2024-06-15T03:12:27.954101Z",
     "shell.execute_reply": "2024-06-15T03:12:27.952051Z",
     "shell.execute_reply.started": "2024-06-15T03:12:27.943368Z"
    }
   },
   "outputs": [],
   "source": [
    "L, l, d = 5, 2, 3\n",
    "K_past = np.random.randn(L, 3)\n",
    "V_past = np.random.randn(L, 3)\n",
    "Q_past = np.random.randn(L, 3)\n",
    "\n",
    "Q_new = np.random.randn(l, 3)\n",
    "K_new = np.random.randn(l, 3)\n",
    "V_new = np.random.randn(l, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d64c607-7446-4e34-8af1-a73304404595",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:12:29.265147Z",
     "iopub.status.busy": "2024-06-15T03:12:29.264565Z",
     "iopub.status.idle": "2024-06-15T03:12:29.274820Z",
     "shell.execute_reply": "2024-06-15T03:12:29.272751Z",
     "shell.execute_reply.started": "2024-06-15T03:12:29.265104Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_custom_matrix(n):\n",
    "    # 创建一个全为负无穷的矩阵\n",
    "    matrix = np.full((n, n), -np.inf)\n",
    "    \n",
    "    # 将下三角部分（包括对角线）设置为0\n",
    "    lower_triangle_indices = np.tril_indices(n)\n",
    "    matrix[lower_triangle_indices] = 0\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47d36d5f-0346-4942-8feb-ecb960b4d257",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:12:32.874580Z",
     "iopub.status.busy": "2024-06-15T03:12:32.874010Z",
     "iopub.status.idle": "2024-06-15T03:12:32.895045Z",
     "shell.execute_reply": "2024-06-15T03:12:32.892941Z",
     "shell.execute_reply.started": "2024-06-15T03:12:32.874537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1 = create_custom_matrix(5)\n",
    "M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b5e6d32-0d9f-4709-80ff-6caaa53c4c82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:12:34.859637Z",
     "iopub.status.busy": "2024-06-15T03:12:34.859046Z",
     "iopub.status.idle": "2024-06-15T03:12:34.965931Z",
     "shell.execute_reply": "2024-06-15T03:12:34.964704Z",
     "shell.execute_reply.started": "2024-06-15T03:12:34.859595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.286, 0.714, 0.   , 0.   , 0.   ],\n",
       "       [0.538, 0.003, 0.459, 0.   , 0.   ],\n",
       "       [0.113, 0.192, 0.431, 0.265, 0.   ],\n",
       "       [0.089, 0.049, 0.625, 0.153, 0.084]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy as sp\n",
    "sp.special.softmax((Q_past.dot(K_past.T))/np.sqrt(3) + M1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1d8c0ad-14e2-4fff-a1e4-5354b3f625eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:12:39.289794Z",
     "iopub.status.busy": "2024-06-15T03:12:39.289465Z",
     "iopub.status.idle": "2024-06-15T03:12:39.301259Z",
     "shell.execute_reply": "2024-06-15T03:12:39.299343Z",
     "shell.execute_reply.started": "2024-06-15T03:12:39.289773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf, -inf, -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf, -inf, -inf, -inf],\n",
       "       [  0.,   0.,   0.,   0., -inf, -inf, -inf],\n",
       "       [  0.,   0.,   0.,   0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M2 = create_custom_matrix(7)\n",
    "M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59462841-c0d5-48c6-ae27-0203986e6716",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:12:41.233938Z",
     "iopub.status.busy": "2024-06-15T03:12:41.233351Z",
     "iopub.status.idle": "2024-06-15T03:12:41.250652Z",
     "shell.execute_reply": "2024-06-15T03:12:41.248574Z",
     "shell.execute_reply.started": "2024-06-15T03:12:41.233894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.286, 0.714, 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.538, 0.003, 0.459, 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.113, 0.192, 0.431, 0.265, 0.   , 0.   , 0.   ],\n",
       "       [0.089, 0.049, 0.625, 0.153, 0.084, 0.   , 0.   ],\n",
       "       [0.116, 0.391, 0.074, 0.148, 0.132, 0.139, 0.   ],\n",
       "       [0.194, 0.443, 0.016, 0.072, 0.129, 0.03 , 0.115]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = np.concatenate([Q_past, Q_new], axis=0)\n",
    "K = np.concatenate([K_past, K_new], axis=0)\n",
    "sp.special.softmax((Q.dot(K.T))/np.sqrt(3) + M2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2bd9aee-2ce2-42dd-a1ef-dd395fdc0ab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:12:43.797936Z",
     "iopub.status.busy": "2024-06-15T03:12:43.797321Z",
     "iopub.status.idle": "2024-06-15T03:12:43.811805Z",
     "shell.execute_reply": "2024-06-15T03:12:43.809734Z",
     "shell.execute_reply.started": "2024-06-15T03:12:43.797891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.292, 0.047, 0.444, 0.109, 0.107],\n",
       "       [0.085, 0.212, 0.298, 0.256, 0.15 ],\n",
       "       [0.294, 0.002, 0.251, 0.08 , 0.372],\n",
       "       [0.098, 0.166, 0.374, 0.23 , 0.132],\n",
       "       [0.089, 0.049, 0.625, 0.153, 0.084]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy as sp\n",
    "sp.special.softmax((Q_past.dot(K_past.T))/np.sqrt(3), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d97d5ab0-3d42-4d81-ac77-94ae21e65c5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:12:45.775877Z",
     "iopub.status.busy": "2024-06-15T03:12:45.775283Z",
     "iopub.status.idle": "2024-06-15T03:12:45.789304Z",
     "shell.execute_reply": "2024-06-15T03:12:45.787277Z",
     "shell.execute_reply.started": "2024-06-15T03:12:45.775835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.227, 0.109, 0.074, 0.101, 0.132, 0.148, 0.21 ],\n",
       "       [0.159, 0.097, 0.393, 0.049, 0.033, 0.188, 0.081],\n",
       "       [0.229, 0.137, 0.022, 0.113, 0.3  , 0.044, 0.156],\n",
       "       [0.406, 0.175, 0.014, 0.051, 0.272, 0.012, 0.07 ],\n",
       "       [0.404, 0.112, 0.029, 0.06 , 0.154, 0.063, 0.178],\n",
       "       [0.201, 0.112, 0.128, 0.097, 0.1  , 0.182, 0.18 ],\n",
       "       [0.162, 0.211, 0.233, 0.112, 0.13 , 0.079, 0.072]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.special.softmax((Q.dot(K.T))/np.sqrt(3), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
